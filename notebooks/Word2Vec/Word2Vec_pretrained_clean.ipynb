{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5339652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "from statistics import median\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pickle\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc77500",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96201373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(file):\n",
    "    \"\"\"Method to handle the preparation of log event data for further usage in NLP learning methods.\n",
    "    Timestamps are being changed to time inbetween events in a certain trace. After that the values are categorized to\n",
    "    to further improve the quality of data\"\"\"\n",
    "    \n",
    "    # Convert the basic csv input into a first dataframe.\n",
    "    df = pd.read_csv('../../logs/'+file, delimiter=';', header=None)\n",
    "    df = df.drop([df.columns[3]], axis=1)\n",
    "    df.columns = ['timestamp','id','event']\n",
    "    \n",
    "    # Converting timestamps to time difference between events in trace. Difference will be in seconds and categorized to\n",
    "    # ease training of the model. First event will therefore always have a '0' value.\n",
    "    \n",
    "    FMT = '%Y-%m-%d %H:%M:%S' # timestamp format\n",
    "    timediff_list = []\n",
    "\n",
    "    for caseID in df['id'].unique():\n",
    "        caseIndex = 0 # Index for each trace dataframe. iterrows() Index represents index in global DF.\n",
    "        first_time = '' # Temp variable to hold the timestamp of the first event. Timestamp will be lost after first iteration.\n",
    "        for index, event in df[df['id'] == caseID].iterrows():\n",
    "            event_time = event['timestamp']\n",
    "            \n",
    "            if caseIndex == 0:\n",
    "                first_time = event_time\n",
    "                timediff_list.append(0.0) # Can't use previous time without previous event. Time differnece is therefore 0.0..\n",
    "            elif caseIndex == 1:\n",
    "                tdelta = datetime.strptime(event_time, FMT) - datetime.strptime(first_time, FMT) # Deduct current from from previous.\n",
    "                timediff_list.append(tdelta.total_seconds())\n",
    "            else: \n",
    "                prev_time = df[df['id'] == caseID].iloc[caseIndex-1]['timestamp'] # Timestamp of previous event.\n",
    "                tdelta = datetime.strptime(event_time, FMT) - datetime.strptime(prev_time, FMT) # Deduct current from from previous.\n",
    "                timediff_list.append(tdelta.total_seconds())\n",
    "            caseIndex += 1\n",
    "    \n",
    "    # Converting the build up timediff_list into a DataFrame, categorizing it and replace the new values with the given timestamps.\n",
    "    timediff_df = pd.DataFrame(timediff_list, columns=['timestamp_diff'])\n",
    "    timediff_df = pd.cut(timediff_df['timestamp_diff'],10, labels=False) # Categorizing differences into 10 bins with same width.\n",
    "    df = pd.concat([timediff_df,df.drop(['timestamp'], axis=1) ], axis=1, join='inner') # Dropping old timestamps and adding new\n",
    "    df['event'] = df['event'].str.lower() # Converting string to lower case.\n",
    "    \n",
    "    # Converting dataframe values into strings and tokenize each event after.\n",
    "    string_list = df.to_string(header=False,index=False,index_names=False).split('\\n')\n",
    "    token_list = [nltk.word_tokenize(event.lower()) for event in string_list] # List containing event tokens.\n",
    "    \n",
    "    # Creating a list containing word tokens for each trace ID.\n",
    "    traceids = df['id'].unique()\n",
    "    trace_list = []\n",
    "    \n",
    "    # Filter for each tradeid and convert each trade into lists, containing the events.\n",
    "    for id in traceids:\n",
    "        df_trace= df.loc[df['id']==id] # df holding the entries for the specific trace ID\n",
    "        traceString = df_trace.to_string(header=False,index=False,index_names=False).split('\\n') # Converting each event into a string\n",
    "        traceToken = [nltk.word_tokenize(event.lower()) for event in traceString]\n",
    "\n",
    "        trace_list.append(traceToken)\n",
    "    \n",
    "    return df, trace_list, token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "700c8441",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, traceToken, tokenList = preprocessing('ecommerce_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c617a238",
   "metadata": {},
   "source": [
    "## Load and Train model with tokenized events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ce2c4fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.35 GiB for an array with shape (2999969, 300) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m total_examples \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcorpus_count\n\u001b[0;32m      7\u001b[0m model_pretrained \u001b[38;5;241m=\u001b[39m KeyedVectors\u001b[38;5;241m.\u001b[39mload_word2vec_format(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/GoogleNews-vectors-negative300.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_pretrained\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_to_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mintersect_word2vec_format(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/GoogleNews-vectors-negative300.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, lockf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(tokenList, total_examples\u001b[38;5;241m=\u001b[39mtotal_examples, epochs\u001b[38;5;241m=\u001b[39mmodel_pretrained\u001b[38;5;241m.\u001b[39miter)\n",
      "File \u001b[1;32m~\\Documents\\ba-eventlogml\\venv\\lib\\site-packages\\gensim\\models\\word2vec.py:493\u001b[0m, in \u001b[0;36mWord2Vec.build_vocab\u001b[1;34m(self, corpus_iterable, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m report_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_vocab(update\u001b[38;5;241m=\u001b[39mupdate, keep_raw_vocab\u001b[38;5;241m=\u001b[39mkeep_raw_vocab, trim_rule\u001b[38;5;241m=\u001b[39mtrim_rule, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    492\u001b[0m report_values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemory\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimate_memory(vocab_size\u001b[38;5;241m=\u001b[39mreport_values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_retained_words\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_lifecycle_event(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_vocab\u001b[39m\u001b[38;5;124m\"\u001b[39m, update\u001b[38;5;241m=\u001b[39mupdate, trim_rule\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(trim_rule))\n",
      "File \u001b[1;32m~\\Documents\\ba-eventlogml\\venv\\lib\\site-packages\\gensim\\models\\word2vec.py:851\u001b[0m, in \u001b[0;36mWord2Vec.prepare_weights\u001b[1;34m(self, update)\u001b[0m\n\u001b[0;32m    849\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_weights()\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 851\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\ba-eventlogml\\venv\\lib\\site-packages\\gensim\\models\\word2vec.py:883\u001b[0m, in \u001b[0;36mWord2Vec.update_weights\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msyn1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msyn1, np\u001b[38;5;241m.\u001b[39mzeros((gained_vocab, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1_size), dtype\u001b[38;5;241m=\u001b[39mREAL)])\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnegative:\n\u001b[1;32m--> 883\u001b[0m     pad \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgained_vocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mREAL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msyn1neg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msyn1neg, pad])\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.35 GiB for an array with shape (2999969, 300) and data type float32"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader\n",
    "model = Word2Vec(vector_size=300, window=4, min_count=1, workers=4)\n",
    "model.build_vocab(tokenList)\n",
    "total_examples = model.corpus_count\n",
    "\n",
    "model_pretrained = KeyedVectors.load_word2vec_format(\"./models/GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "model.build_vocab([list(model_pretrained.key_to_index.keys())], update=True)\n",
    "model.intersect_word2vec_format(\"./models/GoogleNews-vectors-negative300.bin\", binary=True, lockf=1.0)\n",
    "model.train(tokenList, total_examples=total_examples, epochs=model_pretrained.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57b0ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
