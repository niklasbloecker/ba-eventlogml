{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83ee66ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "221952ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(file):\n",
    "    \"\"\"Method to handle the preparation of log event data for further usage in NLP learning methods.\n",
    "    Timestamps are being changed to time inbetween events in a certain trace. After that the values are categorized to\n",
    "    to further improve the quality of data\"\"\"\n",
    "    \n",
    "    # Convert the basic csv input into a first dataframe.\n",
    "    df = pd.read_csv('../../logs/ecommerce_anomalies.csv', delimiter=';', header=None)\n",
    "    df = df.drop([df.columns[3]], axis=1)\n",
    "    df.columns = ['timestamp','id','event']\n",
    "    \n",
    "    # Converting timestamps to time difference between events in trace. Difference will be in seconds and categorized to\n",
    "    # ease training of the model. First event will therefore always have a '0' value.\n",
    "    \n",
    "    FMT = '%Y-%m-%d %H:%M:%S' # timestamp format\n",
    "    timediff_list = []\n",
    "\n",
    "    for caseID in df['id'].unique():\n",
    "        caseIndex = 0 # Index for each trace dataframe. iterrows() Index represents index in global DF.\n",
    "        first_time = '' # Temp variable to hold the timestamp of the first event. Timestamp will be lost after first iteration.\n",
    "        for index, event in df[df['id'] == caseID].iterrows():\n",
    "            event_time = event['timestamp']\n",
    "            \n",
    "            if caseIndex == 0:\n",
    "                first_time = event_time\n",
    "                timediff_list.append(0.0) # Can't use previous time without previous event. Time differnece is therefore 0.0..\n",
    "            elif caseIndex == 1:\n",
    "                tdelta = datetime.strptime(event_time, FMT) - datetime.strptime(first_time, FMT) # Deduct current from from previous.\n",
    "                timediff_list.append(tdelta.total_seconds())\n",
    "            else: \n",
    "                prev_time = df[df['id'] == caseID].iloc[caseIndex-1]['timestamp'] # Timestamp of previous event.\n",
    "                tdelta = datetime.strptime(event_time, FMT) - datetime.strptime(prev_time, FMT) # Deduct current from from previous.\n",
    "                timediff_list.append(tdelta.total_seconds())\n",
    "            caseIndex += 1\n",
    "    \n",
    "    # Converting the build up timediff_list into a DataFrame, categorizing it and replace the new values with the given timestamps.\n",
    "    timediff_df = pd.DataFrame(timediff_list, columns=['timestamp_diff'])\n",
    "    timediff_df = pd.cut(timediff_df['timestamp_diff'],10, labels=False) # Categorizing differences into 10 bins with same width.\n",
    "    df = pd.concat([timediff_df,df.drop(['timestamp'], axis=1) ], axis=1, join='inner') # Dropping old timestamps and adding new\n",
    "    df['event'] = df['event'].str.lower() # Converting string to lower case.\n",
    "    \n",
    "    # Converting dataframe values into strings and tokenize each event after.\n",
    "    string_list = df.to_string(header=False,index=False,index_names=False).split('\\n')\n",
    "    token_list = [nltk.word_tokenize(event.lower()) for event in string_list] # List containing event tokens.\n",
    "    \n",
    "    # Creating a list containing word tokens for each trace ID.\n",
    "    traceids = df['id'].unique()\n",
    "    trace_list = []\n",
    "    \n",
    "    # Filter for each tradeid and convert each trade into lists, containing the events.\n",
    "    for id in traceids:\n",
    "        df_trace= df.loc[df['id']==id] # df holding the entries for the specific trace ID\n",
    "        traceString = df_trace.to_string(header=False,index=False,index_names=False).split('\\n') # Converting each event into a string\n",
    "        traceToken = [nltk.word_tokenize(event.lower()) for event in traceString]\n",
    "\n",
    "        trace_list.append(traceToken)\n",
    "    \n",
    "    return df, trace_list, token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b639167",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, traceToken, tokenList = preprocessing('ecommerce_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd42ee0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'order'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traceToken[2][5][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2a6f621",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('../data/df_pre.pkl')\n",
    "import pickle\n",
    "with open('../data/trace_WordList.pkl', 'wb') as f:\n",
    "    pickle.dump(traceToken,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831381ed",
   "metadata": {},
   "source": [
    "## Timestamps in Preprocessing\n",
    "Zeitstempel in Event Logs bieten eine Herausforderung im Hinblick auf die Verarbeitung in NLP Verfahren. \n",
    "- Durch die hohe Granularität (bis in Sekunden) ist die Chance, sicher wiederholende Werte zu haben gering\n",
    "- Die Modelle können lediglich den Kontext der Wörter \"erkennen\" jedoch nicht die Bedeutung. Es ist davon auszugehen, dass der Unterschied die verschiedene Dauern der Event nicht klar. Inbesondere, da in den Logs selbst nur die eigentlich Zeit und nicht die Dauer festgehalten wird.\n",
    "\n",
    "Im Sinne der weiteren Verwertbarkeit ist daher eine Kategorisierung der jeweiligen Dauer der Events am sinnvollsten. Es gibt noch andere Ansätze wie z.B. des Ausschreiben der Zahlen, um die Verarbeitung der NLP Modelle zu verbessern, bei der Betrachtung bereits trainierter Modelle, sieht man allerdings, dass dies numerische und ausgeschriebene Werte keine beachtenwerte \"Korrelation\" aufweisen.\n",
    "\n",
    "Ein weiterer Vorteil der kategorischen Werte, ist vorallem im späteren Bilden der Trace Vektoren. Da in diesem Schritt die jeweilige Inverse-Document-Frequency der einzelnen Werte angegeben wird, bieten Kategorien hier eine durch die Einschränkung der Ausprägungen hier eine höhere Aussagekraft. Konkrete Zeiten oder die Dauer im Sekundenformat ist als späterer Wert zu unterschiedlich, als das hier mittels IDF eine repräsentative Aussage getroffen werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f0b2726",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_diff</th>\n",
       "      <th>timestamp_diff</th>\n",
       "      <th>timestamp_diff</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(-7.115, 711.5]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-28 08:23:29</td>\n",
       "      <td>854</td>\n",
       "      <td>Website Request served</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>(4980.5, 5692.0]</td>\n",
       "      <td>5233.0</td>\n",
       "      <td>2022-02-28 09:50:42</td>\n",
       "      <td>854</td>\n",
       "      <td>User logged in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>(711.5, 1423.0]</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>2022-02-28 10:07:36</td>\n",
       "      <td>854</td>\n",
       "      <td>Item added to cart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>(5692.0, 6403.5]</td>\n",
       "      <td>5716.0</td>\n",
       "      <td>2022-02-28 11:42:52</td>\n",
       "      <td>854</td>\n",
       "      <td>Item added to cart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>(2134.5, 2846.0]</td>\n",
       "      <td>2694.0</td>\n",
       "      <td>2022-02-28 12:27:46</td>\n",
       "      <td>854</td>\n",
       "      <td>Hermes chosen for shipping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp_diff    timestamp_diff  timestamp_diff            timestamp   id  \\\n",
       "0               0   (-7.115, 711.5]             0.0  2022-02-28 08:23:29  854   \n",
       "1               7  (4980.5, 5692.0]          5233.0  2022-02-28 09:50:42  854   \n",
       "2               1   (711.5, 1423.0]          1014.0  2022-02-28 10:07:36  854   \n",
       "3               8  (5692.0, 6403.5]          5716.0  2022-02-28 11:42:52  854   \n",
       "4               3  (2134.5, 2846.0]          2694.0  2022-02-28 12:27:46  854   \n",
       "\n",
       "                        event  \n",
       "0      Website Request served  \n",
       "1              User logged in  \n",
       "2          Item added to cart  \n",
       "3          Item added to cart  \n",
       "4  Hermes chosen for shipping  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocessing(file):\n",
    "    \"\"\"Method to handle the preparation of log event data for further usage in NLP learning methods.\n",
    "    Timestamps are being changed to time inbetween events in a certain trace. After that the values are categorized to\n",
    "    to further improve the quality of data\"\"\"\n",
    "    \n",
    "    # Convert the basic csv input into a first dataframe.\n",
    "    df = pd.read_csv('../../logs/ecommerce_anomalies.csv', delimiter=';', header=None)\n",
    "    df = df.drop([df.columns[3]], axis=1)\n",
    "    df.columns = ['timestamp','id','event']\n",
    "    \n",
    "    # Converting timestamps to time difference between events in trace. Difference will be in seconds and categorized to\n",
    "    # ease training of the model. First event will therefore always have a '0' value.\n",
    "    \n",
    "    FMT = '%Y-%m-%d %H:%M:%S' # timestamp format\n",
    "    timediff_list = []\n",
    "    for caseID in df['id'].unique():\n",
    "        caseIndex = 0 # Index for each trace dataframe. iterrows() Index represents index in global DF.\n",
    "        first_time = '' # Temp variable to hold the timestamp of the first event. Timestamp will be lost after first iteration.\n",
    "        for index, event in df[df['id'] == caseID].iterrows():\n",
    "            event_time = event['timestamp']\n",
    "            \n",
    "            if caseIndex == 0:\n",
    "                first_time = event_time\n",
    "                timediff_list.append(0.0) # Can't use previous time without previous event. Time differnece is therefore 0.0.\n",
    "            elif caseIndex == 1:\n",
    "                tdelta = datetime.strptime(event_time, FMT) - datetime.strptime(first_time, FMT) # Deduct current from from previous.\n",
    "                timediff_list.append(tdelta.total_seconds())\n",
    "            else: \n",
    "                prev_time = df[df['id'] == caseID].iloc[caseIndex-1]['timestamp'] # Timestamp of previous event.\n",
    "                tdelta = datetime.strptime(event_time, FMT) - datetime.strptime(prev_time, FMT) # Deduct current from from previous.\n",
    "                timediff_list.append(tdelta.total_seconds())\n",
    "            caseIndex += 1\n",
    "    timediff_df = pd.DataFrame(timediff_list, columns=['timestamp_diff'])\n",
    "    df = pd.concat([timediff_df,df ], axis=1, join='inner')\n",
    "    catTime_df = pd.cut(df['timestamp_diff'],10) # Categorizing differences into 10 bins with same width.\n",
    "    catNumTime_df = pd.cut(df['timestamp_diff'],10, labels=False) # Categorizing differences into 10 bins with same width.\n",
    "    df = pd.concat([catNumTime_df, catTime_df, df ], axis=1, join='inner')\n",
    "    return df\n",
    "\n",
    "preprocessing('ecommerce_log').head()\n",
    "#print(preprocessing('ecommerce_log').head().style.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e486c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
